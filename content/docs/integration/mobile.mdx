---
title: Mobile Applications
description: Build voice-first mobile apps with Flutter, React Native, and Kotlin.
icon: Smartphone
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { Callout } from 'fumadocs-ui/components/callout';
import { ShieldAlert, Smartphone, FileAudio, WifiOff } from 'lucide-react';

Mobile apps are the primary way users interact with technology in Ethiopia. Addis AI provides the low-latency infrastructure needed to build responsive Chat and Voice applications on mobile networks.

<Callout title="SDKs Coming Soon" type="info">
  Official SDKs for **Flutter** and **React Native** are in development. 
  
  Currently, we recommend using standard HTTP clients (`http` for Dart, `fetch` for JS, `OkHttp` for Kotlin) pointing to your backend proxy.
</Callout>

## Security: APKs are Public

<div className="flex flex-col p-5 rounded-lg border border-red-500/20 bg-red-500/5 my-6">
  <div className="flex items-center gap-2 mb-2">
    <ShieldAlert className="w-5 h-5 text-red-600" />
    <div className="font-bold text-red-700 dark:text-red-400">Do not embed keys in your App</div>
  </div>
  <div className="text-sm text-fd-muted-foreground mb-3">
    Mobile applications (APKs/IPAs) can be decompiled. If you hardcode your `sk_` key in your Flutter or Android code, **it will be stolen**.
  </div>
  <div className="text-sm font-medium text-fd-foreground">
    <strong>Pattern:</strong> Mobile App ➝ Your Backend (Secure) ➝ Addis AI API.
  </div>
</div>

---

## Integration Patterns

These examples demonstrate how to call the API (conceptually). In production, replace `https://api.addisassistant.com` with `https://your-backend.com/api/proxy` to secure your keys.

### 1. Flutter (Dart)
Flutter is the dominant framework in our ecosystem. Use the `http` package.

<Tabs items={['Chat Request', 'Audio Playback']}>
  <Tab value="Chat Request">
    ```dart
    import 'dart:convert';
    import 'package:http/http.dart' as http;

    Future<String> generateText(String prompt) async {
      // 1. Define endpoint (Use your backend in production)
      final url = Uri.parse('https://api.addisassistant.com/api/v1/chat_generate');
      
      // 2. Prepare payload
      final body = jsonEncode({
        "model": "Addis-፩-አሌፍ",
        "prompt": prompt,
        "target_language": "am",
        "generation_config": {"temperature": 0.7}
      });

      // 3. Send Request
      try {
        final response = await http.post(
          url,
          headers: {
            "Content-Type": "application/json",
            "X-API-Key": "sk_YOUR_KEY", // ⚠️ Move to Backend
          },
          body: body,
        );

        if (response.statusCode == 200) {
          final data = jsonDecode(response.body);
          return data['response_text'];
        } else {
          throw Exception('Failed to load: ${response.statusCode}');
        }
      } catch (e) {
        return "Error: $e";
      }
    }
    ```
  </Tab>
  <Tab value="Audio Playback">
    Playing Base64 audio in Flutter requires decoding to bytes.
    *Dependencies:* `audioplayers`, `path_provider`

    ```dart
    import 'dart:convert';
    import 'dart:io';
    import 'dart:typed_data';
    import 'package:path_provider/path_provider.dart';
    import 'package:audioplayers/audioplayers.dart';

    Future<void> playBase64Audio(String base64String) async {
      // 1. Decode Base64
      Uint8List bytes = base64Decode(base64String);

      // 2. Save to temporary file
      final dir = await getTemporaryDirectory();
      final file = File('${dir.path}/speech.wav');
      await file.writeAsBytes(bytes);

      // 3. Play
      final player = AudioPlayer();
      await player.play(DeviceFileSource(file.path));
    }
    ```
  </Tab>
</Tabs>

### 2. React Native
Similar to the web, but ensure you handle network permissions on Android.

<Tabs items={['API Call']}>
  <Tab value="API Call">
    ```javascript
    const chatWithAddis = async (userMessage) => {
      try {
        const response = await fetch('https://api.addisassistant.com/api/v1/chat_generate', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'X-API-Key': 'sk_YOUR_KEY', // ⚠️ Move to Backend
          },
          body: JSON.stringify({
            prompt: userMessage,
            target_language: 'am'
          }),
        });

        const json = await response.json();
        console.log(json.response_text);
        return json.response_text;
        
      } catch (error) {
        console.error(error);
      }
    };
    ```
  </Tab>
</Tabs>

### 3. Android (Kotlin)
Using `OkHttp` for networking.

<Tabs items={['OkHttp Client']}>
  <Tab value="OkHttp Client">
    ```kotlin
    val client = OkHttpClient()
    val JSON = "application/json; charset=utf-8".toMediaType()

    fun chat(prompt: String) {
        val jsonBody = """
            {
                "prompt": "$prompt",
                "target_language": "am",
                "model": "Addis-፩-አሌፍ"
            }
        """.trimIndent()

        val body = RequestBody.create(JSON, jsonBody)
        val request = Request.Builder()
            .url("https://api.addisassistant.com/api/v1/chat_generate")
            .addHeader("X-API-Key", "sk_YOUR_KEY") // ⚠️ Move to Backend
            .post(body)
            .build()

        client.newCall(request).enqueue(object : Callback {
            override fun onFailure(call: Call, e: IOException) {
                e.printStackTrace()
            }

            override fun onResponse(call: Call, response: Response) {
                response.use {
                    if (!response.isSuccessful) throw IOException("Unexpected code $response")
                    println(response.body!!.string())
                }
            }
        })
    }
    ```
  </Tab>
</Tabs>

---

## Handling Audio (TTS)

Mobile apps often need to play audio generated by our TTS engine. The API returns a **Base64 string**, not a URL.

<div className="grid grid-cols-1 md:grid-cols-2 gap-4 mt-6">
  
  <div className="p-4 border border-fd-border rounded-lg bg-fd-card">
    <h3 className="font-bold flex items-center gap-2 mb-2 text-fd-foreground">
      <FileAudio className="w-4 h-4 text-blue-500" /> 
      Strategy
    </h3>
    <div className="text-sm text-fd-muted-foreground">
      Since you cannot stream Base64 directly into most native media players easily:
      1.  **Decode** the Base64 string to a Byte Array.
      2.  **Write** the bytes to a temporary file (`cache` directory).
      3.  **Play** the file using the device's native player.
    </div>
  </div>

  <div className="p-4 border border-fd-border rounded-lg bg-fd-card">
    <h3 className="font-bold flex items-center gap-2 mb-2 text-fd-foreground">
      <WifiOff className="w-4 h-4 text-orange-500" /> 
      Caching
    </h3>
    <div className="text-sm text-fd-muted-foreground">
      Mobile data in Ethiopia can be expensive. **Always cache the audio file** locally. Hash the input text to create a filename key. If the user requests the same text again, play the local file instead of calling the API.
    </div>
  </div>

</div>

## Best Practices

*   **Permissions:** If using Speech-to-Text, remember to request **Microphone Permission** (`android.permission.RECORD_AUDIO` / `NSMicrophoneUsageDescription`) in your manifest/plist.
*   **Timeouts:** Mobile networks fluctuate. Set your connection timeouts to at least **30 seconds** to avoid `SocketTimeoutExceptions` during long generations.
*   **Background Threading:** Network requests (especially file uploads) should never run on the UI thread. Use `Isolates` in Flutter or `Coroutines` in Kotlin to keep your UI responsive.