---
title: Speech to Text (Transcription)
description: Transcribe audio into text for Amharic and Afan Oromo.
icon: Mic
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { TypeTable } from 'fumadocs-ui/components/type-table';
import { Callout } from 'fumadocs-ui/components/callout';
import { AudioWaveform, Mic, FileAudio, AlertTriangle } from 'lucide-react';

Our Speech-to-Text (STT) technology is powered by specialized models trained to accurately recognize Ethiopian languages. Unlike generic transcription services, our models are optimized for the specific phonemes, accents, and dialects of **Amharic** and **Afan Oromo**.

## Endpoint

<div className="flex items-center gap-2 border border-fd-border p-3 rounded-lg bg-fd-muted/50 font-mono text-sm my-4">
  <span className="bg-blue-600 text-white px-2 py-0.5 rounded text-xs font-bold">POST</span>
  <span className="text-fd-foreground">https://api.addisassistant.com/api/v2/stt</span>
</div>

---

## Usage Guide

This endpoint requires a **`multipart/form-data`** request. You must send the audio file binary along with a JSON string containing the configuration.

### Transcribe a File
Upload an audio file to get the text transcription.

<Tabs items={['cURL', 'JavaScript', 'Python']}>
  <Tab value="cURL">
   Note: 'request_data' must be a stringified JSON object
    ```bash
    curl --location 'https://api.addisassistant.com/api/v2/stt' \
      --header 'x-api-key: sk_YOUR_KEY' \
      --form 'audio=@"/path/to/voice_note.wav"' \
      --form 'request_data="{ \"language_code\": \"am\" }"'
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const formData = new FormData();
    
    // 1. Append the file
    // Assuming 'fileInput' is an HTML <input type="file">
    formData.append("audio", fileInput.files[0]); 

    // 2. Append metadata as a stringified JSON
    formData.append("request_data", JSON.stringify({ 
      language_code: "am" 
    }));

    const response = await fetch("https://api.addisassistant.com/api/v2/stt", {
      method: "POST",
      headers: {
        "x-api-key": "sk_YOUR_KEY"
        // Do NOT set Content-Type header manually for FormData
        // The browser sets it automatically with the boundary
      },
      body: formData
    });

    const data = await response.json();
    console.log("Transcription:", data.data.transcription);
    ```
  </Tab>
  <Tab value="Python">
    ```python
    import requests
    import json

    url = "https://api.addisassistant.com/api/v2/stt"
    headers = {"x-api-key": "sk_YOUR_KEY"}

    # 1. Prepare Metadata
    payload = {
        'request_data': json.dumps({ "language_code": "am" })
    }
    
    # 2. Open File
    files = [
        ('audio', ('voice.wav', open('/path/to/voice.wav', 'rb'), 'audio/wav'))
    ]

    response = requests.post(url, headers=headers, data=payload, files=files)
    
    print(response.json()['data']['transcription'])
    ```
  </Tab>
</Tabs>

---

## API Reference

### Form Data Parameters
These fields are sent as multipart form data.

<TypeTable
  type={{
    'audio': {
      description: 'The audio file binary. Max size 10MB.',
      type: 'file',
      required: true
    },
    'request_data': {
      description: 'A JSON string containing the configuration options (see below).',
      type: 'string (JSON)',
      required: true
    }
  }}
/>

### Request Data Object
These parameters go inside the `request_data` JSON string.

<TypeTable
  type={{
    'language_code': {
      description: 'The spoken language. "am" (Amharic) or "om" (Afan Oromo).',
      type: 'string',
      required: true
    }
  }}
/>

### Response Schema

```json
{
  "status": "success",
  "data": {
    "transcription": "ሰላም እንኳን ደህና መጣችሁ",
    "usage_metadata": {
      "totalBilledDuration": "15s",
      "requestId": "69b60667-0000-2a1e-b6d3-d4f547fe6724"
    }
  },
  "confidence": 0.982
}

```
---

### Supported Formats

We support standard audio containers. For the fastest processing, we recommend **WAV**.

| Format | Content Types (MIME) |
| :--- | :--- |
| **WAV** | `audio/wav`, `audio/x-wav`, `audio/wave` |
| **MP3** | `audio/mpeg`, `audio/mp3` |
| **M4A** | `audio/mp4`, `audio/x-m4a` |
| **WebM** | `audio/webm` |

---
## Best Practices

To ensure high accuracy (WER < 10%), follow these recording guidelines.
<div className="grid grid-cols-1 md:grid-cols-2 gap-4 mt-8">
{/* Audio Quality Card */}
<div className="flex flex-col p-5 rounded-lg border border-fd-border bg-fd-card shadow-sm transition-all hover:border-fd-primary/30">
<div className="flex items-center gap-2.5 mb-4">
<AudioWaveform className="w-4 h-4 text-blue-500" />
<h3 className="font-semibold text-sm text-fd-foreground uppercase tracking-wide">Audio Specs</h3>
</div>
<div className="space-y-3 text-sm text-fd-muted-foreground">
<div>
<strong className="text-fd-foreground">Sample Rate:</strong> 16kHz or higher is recommended for clarity.
</div>
<div>
<strong className="text-fd-foreground">Channel:</strong> Mono is preferred. Stereo files are supported but mixed down before processing.
</div>
</div>
</div>
{/* Environment Card */}
<div className="flex flex-col p-5 rounded-lg border border-fd-border bg-fd-card shadow-sm transition-all hover:border-fd-primary/30">
<div className="flex items-center gap-2.5 mb-4">
<Mic className="w-4 h-4 text-green-500" />
<h3 className="font-semibold text-sm text-fd-foreground uppercase tracking-wide">Environment</h3>
</div>
<div className="space-y-3 text-sm text-fd-muted-foreground">
<div>
<strong className="text-fd-foreground">Noise:</strong> Background noise significantly degrades accuracy. Record in quiet environments.
</div>
<div>
<strong className="text-fd-foreground">Distance:</strong> Keep the speaker 10-30cm from the microphone for optimal volume levels.
</div>
</div>
</div>
{/* Limits Card */}
<div className="flex flex-col p-5 rounded-lg border border-fd-border bg-fd-card shadow-sm transition-all hover:border-fd-primary/30">
<div className="flex items-center gap-2.5 mb-4">
<FileAudio className="w-4 h-4 text-orange-500" />
<h3 className="font-semibold text-sm text-fd-foreground uppercase tracking-wide">Constraints</h3>
</div>
<div className="space-y-3 text-sm text-fd-muted-foreground">
<div className="flex items-center justify-between p-2 rounded bg-fd-secondary/40 border border-fd-border/50">
<span className="text-xs font-medium">Max Duration</span>
<code className="text-xs text-fd-foreground">60 Seconds</code>
</div>
<div className="flex items-center justify-between p-2 rounded bg-fd-secondary/40 border border-fd-border/50">
<span className="text-xs font-medium">Max File Size</span>
<code className="text-xs text-fd-foreground">10 MB</code>
</div>
</div>
</div>
{/* Limitations Card */}
<div className="flex flex-col p-5 rounded-lg border border-fd-border bg-fd-card shadow-sm transition-all hover:border-fd-primary/30">
<div className="flex items-center gap-2.5 mb-4">
<AlertTriangle className="w-4 h-4 text-red-500" />
<h3 className="font-semibold text-sm text-fd-foreground uppercase tracking-wide">Limitations</h3>
</div>
<div className="space-y-3 text-sm text-fd-muted-foreground">
<div>
<strong className="text-fd-foreground">Speakers:</strong> The model is optimized for single-speaker audio. Overlapping voices may result in skipped words.
</div>
<div>
<strong className="text-fd-foreground">Technical Terms:</strong> Rare technical jargon or code-switching (mixing English heavily) may have lower accuracy.
</div>
</div>
</div>
</div>